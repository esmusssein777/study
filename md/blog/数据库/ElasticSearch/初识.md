# ElasticSearch初识

[toc]

## ElasticSearch的历史

* ElasticSearch 是一款基于 Lunece 的开源分布式搜索分析引擎
  * 查询性能好
  * 分布式设计，非常方便的水平扩展
  * 支持多种多种语言的集成
* 超过 2.5 亿的下载量，有良好的开发者社区，更有商业公司的支持

### Elastic Stack 生态



<img src="https://gitee.com/Esmusssein/picture/raw/master/uPic/AaudpE.png" style="zoom: 25%;" />

* 应用场景
  * 网站搜索 / 垂直搜索 /代码搜索
  * 日志管理与分析 / 安全指标监控 / 应用性能监控 / WEB抓取舆情分析



## ElasticSearch 的基本概念

<img src="https://gitee.com/Esmusssein/picture/raw/master/uPic/fwSAVL.png" style="zoom:50%;" />

### 文档（Document）

* ElasticSearch 是面向文档的，文档上所有可搜索数据的最小单位
  * 日志文件中的日志项
  * 一部电影的具体信息
  * 一篇 PDF 文档中的具体消息
* 文档会被序列化成 JSON 格式，保存在 ElasticSearch 中
  * JSON 对象由字段组成
  * 每个字段都有对应的字段类型（字符串 / 数值 / 布尔 / 日期 / 二进制）
* 每个文档都有一个 Unique ID
  * 可以自己指定ID
  * 或者通过 ElasticSearch 主动生成

**文档的元数据**

![](https://gitee.com/Esmusssein/picture/raw/master/uPic/7ENYpp.png)

PS:`_type`在7.0之前可以设置多个Types，7.0之后一个索引只能创建一个Type-“_doc”

### 索引（Index）

* Index 索引是文档的容器，是一类文档的结合
  * Index体现了逻辑概念，每个索引都有自己的 Mapping 定义
  * Shard 体现了物理概念，索引中的数据分散在 Shard 上
* 索引的 Mapping 和 Setting
  * Mapping 定义文档字段的类型
  * Setting 定义不同的数据分布

### REST API 通信

![WumWf5](https://gitee.com/Esmusssein/picture/raw/master/uPic/WumWf5.png)



### 节点

* 节点上一个 ElasticSearch 的实例，本质上一个 Java 进程
* 每个节点都有名字，通过配置文件配置，或者启动时候 -E node.name=node1 指定
* 每个节点在启动后，会分配一个UID，保存在 data 目录下

#### Master-eligible nodes 和 Master Node

* 每个节点启动后，默认就是一个 Master eligible 节点
* Master-eligible 节点可以参加竞选主流程，成为 Master节点
* 当第一个节点启动时，它会将自己选举成 Master 节点
* 每个节点都保存了集群的状态，但只有Master节点才能修改集群的状态消息
  * 集群状态(Cluster State)，维护了一个集群中的消息（所有节点信息、所有索引信息、分片的路由信息）
  * 任意的节点都能修改信息会导致数据的不一致

#### Data Node 和 Coordinating Node

* Data Nod 是可以保存数据的节点，负责保存分片数据，在数据扩展上起到关键作用
* Coordinating Node 负责接收 Client 的请求，将请求分发到合适的节点，最终把结果汇聚到一起，每个节点都默认的起到了Coordinating Node 的职责

#### 其它的节点类型

* Hot & Warm Node
  * 不同硬件配置的 Data Node，用来实现 Hot & Warm 架构，降低集群的部署成本
* Machine Learning Node
  * 负责机器学习来做异常检测之类

**发展过程**

<img src="https://gitee.com/Esmusssein/picture/raw/master/uPic/8LSTpe.png" style="zoom: 33%;" />

### 分片（Primary Shard & Replica Shard）

* 主分片，用来解决数据水平扩展的问题。通过主分片，可以将数据分布到集群的所有节点上
  * 一个分片上一个运行的 Lucene 的实例
  * 主分片数在索引创建时指定，后面不允许修改，除非 Reindex
* 副本，用来解决数据高可用的问题，副本分片是主分片的拷贝
  * 副本分片数，可以动态调整
  * 增加副本数，可以在一定程度提高服务的可用性（读取的吞吐）

![fta6Ef](https://gitee.com/Esmusssein/picture/raw/master/uPic/fta6Ef.jpg)

如图所示，创建一个索引，这个索引可以拆分成多个 `shard`，每个 shard 存储部分数据。多个 shard 的好处是

* **支持横向扩展**，如果你的数据量是 3T，分成 3 个 shard，每个 shard 就是 1T 的数据，若现在数据量增加到 4T，要保持每个 shard 都是1T 的数据，那么重新建一个有 4 个 shard 的索引，将数据导入
* **提高性能**，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能
* **高可用性**，每个 shard 的数据都有多个备份，如果某个机器宕机了还有数据副本在其它的机器上

shard 的数据有多个备份，每个 shard 都有一个 `primary shard`，负责写入数据，还有几个 `replica shard`。`primary shard` 写入数据之后，会将数据同步到其他几个 `replica shard` 上去。

es 集群多个节点，会自动选举一个节点为 master 节点，这个 master 节点负责维护索引元数据、负责切换 primary shard 和 replica shard 身份等。如果 master 节点宕机了，那么会重新选举一个节点为 master 节点。

如果是非 master节点宕机了，那么会由 master 节点，将宕机节点上的 primary shard 的身份转移到其它机器上的 replica shard。接着修复了宕机机器重启了之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据之类的，让集群恢复正常。如果宕机的机器修复了，修复后的节点也不再是 primary shard，而是 replica shard。

上述就是 ElasticSearch 作为分布式搜索引擎最基本的一个架构设计。



### 倒排索引

#### 正排索引和倒排索引

![f5Mnaz](https://gitee.com/Esmusssein/picture/raw/master/uPic/f5Mnaz.png)

* 正排索引：文档ID到文档内容和单词的关联
* 倒排索引：单词到文档ID到关联

#### 倒排索引的核心组成

包括两个部分

* 单词词典（Term Dictionary），记录所有文档的单词，记录单词到倒排列表到关联关系
  * 单词词典一般比较大，可以通过 B+ 树或哈希拉链实现，以满足高性能的插入和查询
* 倒排列表（Posting List），记录单词对应的文档结合，由倒排索引项组成
  * 倒排索引项（Posting）
    * 文档ID
    * 词频 TF - 该单词在文档中出现的次数，用来相关性评分
    * 位置（Posting） - 单词中文档中的位置，用来语句搜索
    * 偏移（Offset） - 记录单词开始和结束的位置，实现高亮显示

​		

###Analysis 和 Analyzer

Analysis 文本分析是把全文本转换一系列单词（term / token）的过程，也叫分词，Analysis 是通过 Analyzer 分词器来实现的。Analyzer是专门处理分词的组件，Analyzer 由三部分组成

* Character Filters - 针对原始文本处理，例如去除html
* Tokenizer  - 按照规则切分为单词
* Token Filter - 将切分的单词进行加工，小写，删除 stopwords，增加同义词

![BTKiF8](https://gitee.com/Esmusssein/picture/raw/master/uPic/BTKiF8.png)

#### Elasticsearch 的内置分词器

* Standard Analyzer-默认分词器,按i切分,小写处理
* Simple Analyzer-按照非字母切分(符号被过滤) ,小写处理
* Stop Analyzer-小写处理,停用词过滤(the, a, is)
* Whitespace Analyzer-按照空格切分,不转小写
* Keyword Analyzer-不分词,直接将输入当作输出
* Patter Analyzer-正则表达式,默认\W+(非字符分隔)
* Language-提供了30多种常见语言的分词器
* Customer Analyzer自定义分词器

#### 中文分词

一句中文，在不同的语境下，有不同的理解

* 这个苹果，不大好吃 / 这个苹果，不大，好吃！

中文分词有很多歧义的语境（组合型歧义、交集型歧义、真歧义）

##### 中文分词的演变

* 查字典 - 最容易想到的分词方法(北京航空大学的梁南元教授提出)
  * 一个句子从左到右扫描一遍。遇到有的词就标示出来。找到复合词,就找最长的
  * 不认识的字串就分割成单字词

* 最小词数的分词理论 - 哈工大王晓龙博士把查字典的方法理论化
  * 一句话应该分成数量最少的词串
  * 遇到二义性的分割，无能为力（例如:“发展中国家” /“上海大学城书店"）
  * 用各种文化规则来解决二义性,都并不成功

* 统计语言模型-1990年前后,清华大学电子工程系郭进博士
  * 解决了二义性问题,将中文分词的错误率降低了一个数量级。概率问题,动态规划+利用维特比算法快速找到最佳分词

* 基于统计的机器学习算法
  * 这类目前常用的是算法是HMM、CRF、 SVM、深度学习等算法。比如Hanlp分词工具是基于CRF算法以CRF为例，基本思路是对汉字进行标注训练,不仅考虑了词语出现的频率,还考虑上下文,具备较好的学习能力，因此其对歧义词和未登录词的识别都具有良好的效果。
  * 随着深度学习的兴起,也出现了基于神经网络的分词器,有人尝试使用双向LSTM+CRF实 分词器,其本质上是序列标注,据报道其分词器字符准确率可高达97.5%

###### ICU Analyzer

<img src="https://gitee.com/Esmusssein/picture/raw/master/uPic/fHtrDa.png" alt="fHtrDa" style="zoom:50%;" />

### 聚合(Aggregation)

* Elasticsearch 除了搜索以外，提供的针对 ES 数据进行统计分析的功能
  * 实时性高，Hadoop需要 (T+1) 天
* 通过聚合，我们得到的是一个数据的概览，是分析和总结的数据，而不是单个文档
* 高性能，只需要一句语句，就可以从 Elasticsearch中得到分析结果，无需自己去实现逻辑

#### 集合的分类

* Bucket Aggregation - 一些列满足特定的文档的集合
* Metric Aggregation - 一些数学运算，可以对文档字段进行统计分析（min / max / avg / sum / cardinality）
* Pipeline Aggregation - 对其它的聚合结果进行二次聚合
* Matrix Aggregation - 支持对多个字段的操作并提供一个结果矩阵

## ElasticSearch 的工作机制

###写入数据

- 客户端选择一个 node 发送请求，这个 node 就是 `coordinating node`（协调节点）。
- `coordinating node` 对 document 进行**路由**，将请求转发给对应的 node（有 primary shard）。
- 实际的 node 上的 `primary shard` 处理请求，然后将数据同步到 `replica node`。
- `coordinating node` 在发现 `primary node` 和所有 `replica node` 都完成之后，就返回响应结果给客户端。

![2ARRY7](https://gitee.com/Esmusssein/picture/raw/master/uPic/2ARRY7.jpg)

### 读取数据

- 客户端发送请求到**任意**一个 node，成为 `coordinate node`。
- `coordinate node` 对 `doc id` 进行哈希路由，将请求转发到对应的 node，此时会使用 `round-robin` **随机轮询算法**，在 `primary shard` 以及其所有 replica 中随机选择一个，让读请求负载均衡。
- 接收请求的 node 返回 document 给 `coordinate node`。
- `coordinate node` 返回 document 给客户端。

### 搜索数据

- 客户端发送请求到一个 `coordinate node`。
- 协调节点将搜索请求转发到**所有**的 shard 对应的 `primary shard` 或 `replica shard`。
- query phase：每个 shard 将自己的搜索结果（其实就是一些 `doc id`）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。
- fetch phase：接着由协调节点根据 `doc id` 去各个节点上**拉取实际**的 `document` 数据，最终返回给客户端。

### 数据的生命周期

#### 写入数据

* 在Lucene中，单个倒排索引文件被称为Segment。 Segment是自包含的，不可变更的。多个Segments汇总在一起,称为Lucene的Index，其对应的就是ES中的Shard。

* 当有新文档写入时，会生成新Segment，查询时会同时查询所有Segments，并且对结果汇总。Lucene中有一个文件，用来记录所有Segments信息，叫做Commit Point。

* 删除的文档信息，保存在".del"文件中。

<img src="https://gitee.com/Esmusssein/picture/raw/master/uPic/5bz0Ij.jpg" alt="5bz0Ij" style="zoom:67%;" />

1. 首先将写入内存 buffer 中，同时写入 translog 日志文件，此时数据不可以被搜索到。

2. 如果 buffer 满了，或者每隔 1 秒钟(可修改)，es 将 buffer 中的数据写入一个**新的** `segment file`，每秒钟会产生一个**新的磁盘文件** `segment file`，这个 `segment file` 中就存储最近 1 秒内 buffer 中写入的数据。

3. 但是因为直接写入磁盘的代价很大，所以此时数据不是直接进入磁盘，而是先进入 `os cache` 内存中。这个过程就是 `refresh`。只要 `buffer` 中的数据被 refresh 操作刷入 `os cache`中，这个数据就可以被搜索到了。

4. 新的数据不断进入 buffer 和 translog，不断将 `buffer` 数据写入一个又一个新的 `segment file` 中去，每次 `refresh` 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 `commit` 操作。

5. commit 操作发生第一步，就是将 buffer 中现有数据 `refresh` 到 `os cache` 中去，清空 buffer。然后，将一个 `commit point` 写入磁盘文件，里面标识着这个 `commit point` 对应的所有 `segment file`，同时强行将 `os cache` 中目前所有的数据都 `fsync` 到磁盘文件中去。最后**清空** 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。这个 commit 操作叫做 `flush`。默认 30 分钟自动执行一次 `flush`，但如果 translog 过大，也会触发 `flush`。

#### 删除数据

如果是删除操作，commit 的时候会生成一个 `.del` 文件，里面将某个 doc 标识为 `deleted` 状态，那么搜索的时候根据 `.del` 文件就知道这个 doc 是否被删除了。

如果是更新操作，就是将原来的 doc 标识为 `deleted` 状态，然后新写入一条数据。

buffer 每 refresh 一次，就会产生一个 `segment file`，所以默认情况下是 1 秒钟一个 `segment file`，这样下来 `segment file` 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 `segment file` 合并成一个，同时这里会将标识为 `deleted` 的 doc 给**物理删除掉**，然后将新的 `segment file` 写入磁盘，这里会写一个 `commit point`，标识所有新的 `segment file`，然后打开 `segment file` 供搜索使用，同时删除旧的 `segment file`。